---
title: "BACPAC Simulation - Code explainer"
output: html_notebook
---

```{r packages and scripts, echo = FALSE, warning = FALSE, message = FALSE, results = 'hide'}
library(tidyverse)
library(DynTxRegime)
scripts <- str_subset(list.files(), ".R$")
quietly(map(scripts, source))
```

__Overview of simulation code___

The basic skeleton for creating the simulation is the following:

Step 1: Generate participants and their covariates

a. Generate participants
b. Generate covariates

Step 2: Generate the trial

a. Allocate first-line treatments
b. Generate Y1 and responder status
c. Allocate second-line treatments
d. Generate Y2 
e. Generate Y 

Step 3: Wrap up Steps 1 and 2 in a wrapper to create many data sets

Step 4: map-reduce to put all the simulation data together (reduce optional)

Step 5: Analyze the simulation data sets and assess power given the simulation parameters

__Steps 1 and 2__

Because the design of the trial is evolving, the simulation code is written with maximum flexibility and tractability in mind. Every simulation study starts with a plan which includes a design and a mechanism for generating participants and their outcomes. **The design and participants are operationalized through 8 functions choices where each function represents a key design or participant generation aspect.** The function choices are: 1. making participants, 2. making covariates, 3. allocating stage 1 treatments, 4. generating Y1, 5. assigning responder status, 6. allocating stage 2 treatments based on responder status, 7. generating Y2, and 8. generating Y. **The fundamental code design principle is to be tidy.** Specifically, the fundamental object is a dataframe that is piped through the 8 key functions and a dataframe is the yielded output. Once more of the design is nailed down, we may want to re-code this to utilize faster data objects.

I've made corresponding wrapper functions to show how functions you write/choose for each design choice should work. The first function is `makePpts()`. It is parameterized by an integer `N` and returns a dataframe with `N` rows and a single variable `ptid` (patient identifier).

```{r}
set.seed(309482)
# Some parameters we will need
N <- 100
firstLineTreatments <- as.character(1:6)
secondLineTreatments <- c("2", "3", "7", "8")
augmentationTreatments <- c("a1", "a2")
standardOfCareTreatment <- "1"

simDF <- makePpts(N = N)

simDF
```

The second function is `makeCovariates()`. Because this is a SMART and the goal is to answer precision medicine questions, generating covariates and relationship between them will be key. `makeCovariates()` takes the fundamental dataframe, a covariate generating function `covariateFn`, and related parametners for `covariateFn` and returns the fundamental dataframe with the covariates appended. 

Note that `covariateFn` is a function written to generate covariates. Check the library of written functions to see if there is a function that you can use or write your own to the library. In the snippet below, I have passed a function I wrote called `covariateFn_v1` and it takes 5 parameters (that are in the varargs position). 

```{r}
simDF <- simDF %>%
  makeCovariates(covariateFn = covariateFn_v1, 
                   numBinaryCovars = 3, props = c(0.6, 0.5, 0.4),
                   numNormalCovars = 1, mu = 0, sd = 1)

simDF
```

The third function is `allocateSTage1Treatments()`. It takes a function that defines how to allocate firstline treatments and associate parameters (varargs). Note that the firstline treatment assignment is named `A1`. Let's try to use this naming convention.

```{r}
simDF <- simDF %>%
   allocateStage1Treatments(allocationFn_stage1_v1, 
                             firstLineTreatments = firstLineTreatments)

simDF  
```

The fourth function is `generateY1()`. As you can see now, the general pattern is that each of the 8 key functions take a function and its associated parameters as its arguments. 

```{r}
simDF <- simDF %>%
  generateY1(generateY1Fn = generateNormalY1, 
               intercept = 1, 
               coefs = c("X_1" = -1, "W_1" = 1, "A1_2*W_1" = 0.5), 
               sigma = 1)

simDF
```

The fifth function is `assignResponderStatus()`, the sixth function is `allocateStage2Treatments()`, the seventh function is `generateY2()`, and the eighth function is `generateY()`.

```{r}
simDF <- simDF %>%  assignResponderStatus(assignResponderStatusByQuantile, 
                          ctsOutcome1 = Y1, cutoffs = c(0.2, 0.8)) %>%
    allocateStage2Treatments(allocationFn_stage2 = allocationFn_stage2_v1,
                             firstLineTreatments = firstLineTreatments,
                             secondLineTreatments = secondLineTreatments,
                             augmentationTreatments = augmentationTreatments,
                             standardOfCareTreatment = standardOfCareTreatment) %>%
    generateY2(generateY2Fn_v1, coefs = c("A1_1*X_1" = 1, "X_1" = 2, "A2_7*W_1" = 1),
               sigma = 1) %>%
    generateY(generateYFn = setYtoY2)
  
simDF
```


__Step 3__

Obviously, we don't want to go through each step for every simulation, so here is how you can wrap up the code into a single function. The only addition is a an additional column appended to each dataframe to keep track of which simulation data is being created. You will need to create metadata and args with the named elements as below. Note that the `args` list does exactly what we did above--for each step it lists a function name to use for the key step and the corresponding arguments. 

```{r}
metadata <- list(N = 600,
                 firstLineTreatments = as.character(1:6),
                 secondLineTreatments = c("2", "3", "7", "8"),
                 augmentationTreatments = c("a1", "a2"),
                 standardOfCareTreatment = "1")
args <- list(
  makePpts_fn = "makePpts",
  makePpts_args = list(metadata[["N"]]),
  makeCovariates_fn = "covariateFn_v1",
  makeCovariates_args = list(numBinaryCovars = 3, props = c(0.6, 0.5, 0.4),
                             numNormalCovars = 1, mu = 0, sd = 1),
  allocateStage1Treatments_fn = "allocationFn_stage1_v1",
  allocateStage1Treatments_args = list(metadata$firstLineTreatments),
  generateY1_fn = "generateNormalY1",
  generateY1_args = list(intercept = 1, 
                         coefs = c("X_1" = -1, "W_1" = 1, "A1_2*W_1" = 0.5), 
                         sigma = 1),
  assignResponderStatus_fn = "assignResponderStatusByQuantile",
  assignResponderStatus_args = list(ctsOutcome1 = "Y1", cutoffs = c(0.2, 0.8)),
  allocateStage2Treatments_fn = "allocationFn_stage2_v1",
  allocateStage2Treatments_args = list(firstLineTreatments = metadata$firstLineTreatments,
                                       secondLineTreatments = metadata$secondLineTreatments,
                                       augmentationTreatments = metadata$augmentationTreatments,
                                       standardOfCareTreatment = metadata$standardOfCareTreatment),
  generateY2_fn = "generateY2Fn_v1",
  generateY2_args = list(coefs = c("A1_1*X_1" = 1, "X_1" = 2, "A2_7*W_1" = 1),
                         sigma = 1),
  generateY_fn = "setYtoY2",
  generateY_args = NULL
)


makeSimDataWrapper(metadata, args, 1) 

```


__Step 4__

Here's how you would use your wrapper function from Step 3 to make `L` simulation data sets. 

```{r}
set.seed(309482)

# Create L data sets
L <- 100
# allSimData <- reduce(map(1:L, makeSimDataWrapper, metadata = metadata, args = args), bind_rows)
allSimData <- map(1:L, makeSimDataWrapper, metadata = metadata, args = args)
```

__Step 5__

Analyze the data sets we can estimate the optimal DTR using Q-learning. 

```{r}
moMain <- modelObj::buildModelObj(model = ~ X_1 + X_2 + X_3 + W_1,
                                  solver.method = 'lm')
moCont <- moMain

res <- map(allSimData, doQLearning, moMain_stage2 = moMain, moCont_stage2 = moCont,
            moMain_stage1 = moMain, moCont_stage1 = moCont)
estimatedValues <- map(res, estimator)
unlist(estimatedValues)
```
